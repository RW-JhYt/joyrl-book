# 前言

## 内容提要

$\qquad$ 继《蘑菇书》之后，我们对于想要更多地深入了解强化学习实践的读者准备了一套全新的教程，全书主要基于笔者“不那么丰富可是也有一点咯”的实践经验，帮助读者快速入门强化学习的代码实践，并辅以一套开源代码框架 $\text{JoyRL}$ ，便于读者适应业界应用研究风格的代码。

$\qquad$ 与《蘑菇书》不同，本教程侧重对强化学习核心理论的提点和串联，以及对于强化学习代码实践的指导，尽可能还原原论文的主要思想，而不是对于理论的详细讲解。因此，《蘑菇书》适合适合细嚼慢咽的读者，而本教程则适合具有一定编程基础且希望快速进入实践应用的读者。

## 前言

$\qquad$ 在前几年，我们 “磨菇书三剑客” 已经在 $\text{Github}$ 上发布过线上教程 $\text{EasyRL}$，并填补了强化学习国内相关资料较少的空缺。特此再次衷心感谢李宏毅、周博磊、李科浇三位老师的授权与开源奉献精神，没有他们的鼓励与无私，就没有能够造福广大强化学习初学者的《蘑菇书》。并且受到广大读者的鼓励，我们在这过程中不断优化教程，以期帮助读者更好、更愉快地入门强化学习。

$\qquad$ 时光荏苒，笔者已在业界深耕一年有余， 对于强化学习实践有了更加深入的认识，并对理论与实践的结合方面也产生了一些小小的心得。与此同时，我们也发现了读者们在从理论转变到实践的过程中似乎存在着一定的鸿沟。一方面，很多已经有人工智能知识基础的读者只是想应用强化学习来做一些其他方面的交叉研究，但由于强化学习理论错综复杂，对于这样的初学者来说很难在短时间内快速把握重点，并容易陷入一些对于实践关系不大的小知识点中。另一方面来讲，也有一些读者很难讲强化学习中的论文公式和实际代码相对应起来，例如策略函数的设计等等，并且对于算法的各种超参数调整也不知从何下手。

$\qquad$ 尽管市面上已经有一些实践教程的书籍了，但这些教程往往又过于偏重实践，忽视了理论与实践之间的把握与平衡。此外，相关的实践内容也往往偏向于一些简单的实验和算法，涵盖的内容也不够全面。鉴于这些现状，笔者希望让读者更加凝练和全面地对强化学习知识有一个更深入的了解，这也是本教程发布的初衷。

$\qquad$ 全书的内容主要基于笔者的理论知识与实践经验累积，并伴有一些原创内容的发散，例如针对策略梯度算法，提供了两种不同的推导版本，以便于让读者从不同的角度更好地理解相关知识。并且在全文中始终贯穿强化学习实践中的一些核心观点，比如优化值的估计、解决探索与利用等问题。全书对于内容结构进行了合理地编排，例如从传统强化学习到深度强化学习过渡的章节中，增加了对于深度学习基础的总结归纳，并对于一些十分泛用的强化学习算法比如 $\text{DQN}$、$\text{DDPG}$ 以及 $\text{PPO}$ 等算法作了强调，读者可择取阅读。除了给出一些简单的配套代码演示之外，笔者还开发了一套 $\text{JoyRL}$ 开源框架，并提供了更多复杂环境的 $\text{Benchmark}$，对于想要深入了解的读者可自行研究。

$\qquad$ 本书由开源组织 $\text{Datawhale}$ 的成员采用开源协作的方式完成，历时一年有余，主要参与者包括编著者（笔者、王琦和杨毅远）。此外，也十分感谢谌蕊（清华大学）、丁立（上海交通大学）、郭事成、孙成超、刘二龙（南京大学）、潘笃驿等同学参与 $\text{JoyRL}$ 开源框架的共建。在本书写作和出版过程中，人民邮电出版社提供了很多出版的专业意见和支持，在此特向信息技术出版社社长陈冀康老师和本书的责任编辑郭媛老师致谢。

$\qquad$ 笔者水平有限，书中难免有疏漏和表述不当之处，还望读者批评指正。




