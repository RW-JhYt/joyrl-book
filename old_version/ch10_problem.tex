\subsection{关键词}

设计奖励（reward shaping）：当智能体与环境进行交互时，我们人为设计一些奖励，从而“指挥”智能体，告诉其采取哪一个动作是最优的。需要注意的是，这个奖励区别于环境的奖励。其可以提高我们估算Q函数时的准确性。

内在好奇心模块（intrinsic curiosity module，ICM）：其代表好奇心驱动这个技术中的增加新的奖励函数以后的奖励函数。

课程学习（curriculum learning）：一种广义的用在强化学习中训练智能体的方法，其在输入训练数据的时候，采取由易到难的顺序进行输入，也可以人为设计它的学习过程。这个方法在机器学习和强化学习中普遍使用。

逆课程学习（reverse curriculum learning）：相较于课程学习，逆课程学习为更广义的方法。其从最终最理想的状态[我们称之为黄金状态（gold state）]开始，依次去寻找距离黄金状态最近的状态作为想让智能体达到的阶段性的“理想”状态。当然，我们会在此过程中有意地去掉一些极端的状态，即太简单、太难的状态。综上，逆课程学习是从黄金状态反推的方法。

分层强化学习（hierarchical reinforcement learning）：将一个大型的任务，横向或者纵向地拆解成由多个智能体去执行的子任务。其中，有一些智能体负责比较高层次的任务，如负责定目标，定完目标后，再将目标分配给其他的智能体执行。


\subsection{习题}

\kw{10-1} 解决稀疏奖励的方法有哪些？

\kw{10-2} 设计奖励存在什么主要问题？

\kw{10-3} 内在好奇心模块是什么？我们应该如何设计内在好奇心模块？
