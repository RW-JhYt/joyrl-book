\subsection{关键词}

深度确定性策略梯度（deep deterministic policy gradient，DDPG）：在连续控制领域经典的强化学习算法，是深度Q网络在处理连续动作空间的一个扩充方法。具体地，从命名就可以看出，“深度”表明使用了深度神经网络；“确定性”表示其输出的是一个确定的动作，可以用于连续动作环境；“策略梯度”代表的是它用到的是策略网络，并且每步都会更新一次，其是一个单步更新的策略网络。其与深度Q网络都有目标网络和经验回放的技巧，在经验回放部分是一致的，在目标网络的更新上有些许不同。


\subsection{习题}

\kw{12-1} 请解释随机性策略和确定性策略，两者有什么区别？

\kw{12-2} 对于连续动作的控制空间和离散动作的控制空间，如果我们都采取策略网络，应该分别如何操作？


\subsection{面试题}

\kw{12-1} 友善的面试官：请简述一下深度确定性策略梯度算法。

\kw{12-2} 友善的面试官：请问深度确定性策略梯度算法是同策略算法还是异策略算法？请说明具体原因并分析。

\kw{12-3} 友善的面试官：你是否了解过分布的分布式深度确定性策略梯度算法（distributed distributional deep deterministic policy gradient，D4PG）呢？请描述一下吧。
